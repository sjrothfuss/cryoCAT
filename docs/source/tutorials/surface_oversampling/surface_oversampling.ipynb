{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cryocat import cryomap\n",
    "from cryocat import surfsamp\n",
    "from cryocat import cryomotl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All steps should be completed within seconds/minutes. The boundary_sampling and inner_and_outer_pc might took longer depend on the amount of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data and expected output for this tutorial was available in 'tests/test_data/point_clouds,'. The expected output of muti-tomograms example can be found in 'cryoCAT/tests/test_data/point_clouds/motls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading shape labels and sampling the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a shape label stored in a CSV file containing layer number and point coordinates (V, 4) into the SamplePoints class and then sample the surface. Sample points were positioned along the edges of the convex hull formed by the input coordinates. Each point will be assigned a normal vector perpendicular to the surface. The sampling distance between points can be specified by the user based on their needs, with a default value of 1 unit if not provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spcsv = surfsamp.SamplePoints.load(\"../../../../tests/test_data/point_clouds/040_1_shape.csv\")\n",
    "spcsv.boundary_sampling(sampling_distance = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading mask and sampling the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a mask into the SamplePoints class and then sample the mask boundary. Sample points were positioned at the edge of the mask with a normal vector perpendicular to the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spmask = surfsamp.SamplePoints.load(\"../../../../tests/test_data/point_clouds/masks/040_generated_mask_2.mrc\")\n",
    "spmask.boundary_sampling(sampling_distance = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the sampling points into motl_list.em file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points will be written into a motl_list file, where only the x, y, z, phi, psi, and theta columns are filled, while all other columns are set to 0 by default. Users can specify additional columns by providing an input_dict, where the keys correspond to the column names to be filled, and the values are NumPy arrays of shape (V, 1), where V matches the number of points.\\\n",
    "In this example,\n",
    "- spmask example saves the sample points with tomo_id and object_id filled.\n",
    "- spcsv example only saves the sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomo_id = '040'\n",
    "obj_id = '001'\n",
    "input_dict = {'tomo_id':np.ones(spmask.vertices.shape[0])*float(tomo_id), 'object_id':np.ones(spmask.vertices.shape[0])*float(obj_id)}\n",
    "spmask.write(\"../../../../tests/test_data/point_clouds/motl_040mask_sp10.em\", input_dict)\n",
    "spcsv.write(\"../../../../tests/test_data/point_clouds/motl_040csv_sp10.em\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset normal of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point cloud generated by `boundary_sampling` can also be used to replace the normals in a motl_list. The normal of the nearest point to each motl point will be used to update its angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for making the oversample points in right binning\n",
    "b_factor = 4\n",
    "pal_thickness = 20\n",
    "samp_dist = 10\n",
    "\n",
    "mask = cryomap.read(\"../../../../tests/test_data/point_clouds/masks/040_generated_mask_2.mrc\")\n",
    "# bin mask base on b_factor\n",
    "size = tuple(b_factor*i for i in mask.shape)\n",
    "bin_mask = resize(mask, size, order=0, mode='constant')\n",
    "# generate oversample points using bin mask\n",
    "spmask40 = surfsamp.SamplePoints.load(bin_mask)\n",
    "spmask40.boundary_sampling(sampling_distance = samp_dist)\n",
    "spmask40out,_ = spmask40.inner_and_outer_pc(thickness = pal_thickness*b_factor)\n",
    "# load motl which you want to modified\n",
    "motl = cryomotl.Motl.load('../../../../tests/test_data/point_clouds/motl_040_STAexample.em')\n",
    "spmask40out.reset_normals(motl)\n",
    "motl.write_out('../../../../tests/test_data/point_clouds/motl_040_STArenormal.em')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate surface area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may notice that spmask has twice the area of spcsv.\n",
    "# This is because the mask input represents a shell, whereas spcsv only considers the outer surface.\n",
    "print(spmask.area)\n",
    "print(spcsv.area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the mask surface and generating a motl_list for multiple tomograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple tomograms, here is an example script to process them all together.\\\n",
    "_User inputs_\n",
    "- _mask_folder: Path to the folder containing input masks._\n",
    "- _output_folder: Path to the folder where the output motl_list files will be saved._\n",
    "- _mask_list: An (V, 3) excel file with information of masks. V is equals to number of ojects and there's one mask for each object._\n",
    "- _pal_thickness: Thickness of the shell in the mask, used to separate the inner and outer layers of the point clouds._\n",
    "- _sampling_dist: the distance between sampling points in pixels._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling and create point clouds base on the surface of the mask. Keep only the outer shell of the pointcloud and save into a motl_list\n",
    "mask_folder = f'../../../../tests/test_data/point_clouds/masks'\n",
    "mask_list = f'../../../../tests/test_data/point_clouds/mask_list.csv'\n",
    "output_folder = f'../../../../tests/test_data/point_clouds/motls'\n",
    "pal_thickness = 20\n",
    "sampling_dist = 5\n",
    "shift_dist = -6\n",
    "\n",
    "# read in mask_list\n",
    "mask_array = pd.read_csv(mask_list, header=None).to_numpy().astype(str)\n",
    "# zero-padded tomo number to 3 digits\n",
    "mask_array[:, 0] = np.char.zfill(mask_array[:, 0], 3)\n",
    "for i in mask_array:\n",
    "    tomo_id, obj_id = i\n",
    "    # file name of input and output\n",
    "    mask_file = f'{tomo_id}_generated_mask_{obj_id}.mrc'\n",
    "    motl_file = f'{tomo_id}_{obj_id}_pointcloud.em'\n",
    "    mask = cryomap.read(f'{mask_folder}/{mask_file}')\n",
    "    # sampling at the surface of mask and keeping only the outer sample points of the shell\n",
    "    sp = surfsamp.SamplePoints.load(mask)\n",
    "    sp.boundary_sampling(sampling_distance = sampling_dist)\n",
    "    outer_sp,_ = sp.inner_and_outer_pc(thickness = pal_thickness)\n",
    "    # shifting coordinates 6 pixels in opposite normal vectors direction. negative value for shifting into direction opposite of the normal vectors\n",
    "    outer_sp.shift_points(shift_dist)\n",
    "    # create input_dict to fill in 'tomo_id' and 'object_id'\n",
    "    input_dict = {'tomo_id':np.ones(outer_sp.vertices.shape[0])*float(tomo_id), 'object_id':np.ones(outer_sp.vertices.shape[0])*float(obj_id)}\n",
    "    outer_sp.write(f'{output_folder}/{motl_file}', input_dict)\n",
    "    print(f'{motl_file} was written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you would like to shift different distance for different normals use method `shift_points_in_groups` with shift_dict input. The shift_dict is a dictionary where keys are tuples representing normal vectors and values are the shift magnitudes in pixels. Here's an example of shifting points with normals pointing out/into the tomogram with a distance in 20 pixels and others in -6 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_dist = -6\n",
    "shift_dist_tb = 10\n",
    "# To create a shift_dict with keys from all normal vectors\n",
    "shift_dict = {key: shift_dist for key in tuple(map(tuple,outer_sp.normals))}\n",
    "# assgin different value for target normal vectors\n",
    "shift_dict[(1,0,0)] = shift_dist_tb\n",
    "shift_dict[(-1,0,0)] = shift_dist_tb\n",
    "# run shift_points_in_groups\n",
    "outer_sp.shift_points_in_groups(shift_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging and renumbering all motls from each object into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motl_name = sorted(os.listdir(output_folder))\n",
    "motl_merge = cryomotl.Motl.merge_and_renumber([f'{output_folder}/{i}' for i in motl_name])\n",
    "motl_merge.write_out(f'{output_folder}/allmotl_pcShift-6.em')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
