{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Dependencies"
=======
    "## Surface Oversampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "* Crycoat should be installed\n",
    "```\n",
    "pip install cryocat\n",
    "```\n",
    "\n",
    "* Napari should be installed within the environment for the contour drawing:\n",
    "\n",
    "```\n",
    "pip install napari\n",
    "```\n",
    "\n",
    "* The ipython environment should be installed as well for napari to run from the notebook:\n",
    "```\n",
    "pip install --user ipykernel\n",
    "```"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
<<<<<<< HEAD
    "from cryocat import cryomap\n",
    "from cryocat import surfsamp\n",
    "from cryocat import cryomotl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All steps should be completed within seconds/minutes. The boundary_sampling and inner_and_outer_pc might took longer depend on the amount of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data and expected output for this tutorial was available in 'tests/test_data/point_clouds,'. The expected output of muti-tomograms example can be found in 'cryoCAT/tests/test_data/point_clouds/motls."
=======
    "# Import libraries\n",
    "import mrcfile\n",
    "import napari\n",
    "import os\n",
    "import numpy as np\n",
    "from cryocat import cryomotl\n",
    "from cryocat import cuboid_sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected time\n",
    "* All steps (apart from the contour drawing that is user-dependent) should be completed within seconds/minutes"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Loading shape labels and sampling the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a shape label stored in a CSV file containing layer number and point coordinates (V, 4) into the SamplePoints class and then sample the surface. Sample points were positioned along the edges of the convex hull formed by the input coordinates. Each point will be assigned a normal vector perpendicular to the surface. The sampling distance between points can be specified by the user based on their needs, with a default value of 1 unit if not provided."
=======
    "### Input data\n",
    "* The data for this tutorial can be downloaded [here](https://oc.biophys.mpg.de/owncloud/s/XRL6qqNbMQ4FH6e).\n",
    "* In the inputs folder are all files necessary to run following codes.\n",
    "* In the expected_outputs folder are output files that should be produced by this analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw contour on Napari\n",
    "In the napari GUI, a new shape layer was created, and the contour was drawn using the \"add polygons\" button.\n",
    "Drawing contours on multiple axes can enhance the accuracy of sampling points on the target surfaces."
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "spcsv = surfsamp.SamplePoints.load(\"../../../../tests/test_data/point_clouds/040_1_shape.csv\")\n",
    "spcsv.boundary_sampling(sampling_distance = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading mask and sampling the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a mask into the SamplePoints class and then sample the mask boundary. Sample points were positioned at the edge of the mask with a normal vector perpendicular to the surface."
=======
    "mrcfolder = './inputs/'\n",
    "shapefolder = './inputs/'"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "spmask = surfsamp.SamplePoints.load(\"../../../../tests/test_data/point_clouds/masks/040_generated_mask_2.mrc\")\n",
    "spmask.boundary_sampling(sampling_distance = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the sampling points into motl_list.em file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points will be written into a motl_list file, where only the x, y, z, phi, psi, and theta columns are filled, while all other columns are set to 0 by default. Users can specify additional columns by providing an input_dict, where the keys correspond to the column names to be filled, and the values are NumPy arrays of shape (V, 1), where V matches the number of points.\\\n",
    "In this example,\n",
    "- spmask saves the sample points with tomo_id and object_id filled.\n",
    "- spcsv only saves the sample points."
=======
    "tomo_num = 40\n",
    "padd_num = str(tomo_num).zfill(3)\n",
    "obj_num = 1\n",
    "sample_distance = 3"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "tomo_id = '040'\n",
    "obj_id = '001'\n",
    "input_dict = {'tomo_id':np.ones(spmask.vertices.shape[0])*float(tomo_id), 'object_id':np.ones(spmask.vertices.shape[0])*float(obj_id)}\n",
    "spmask.write(\"../../../../tests/test_data/point_clouds/motl_040mask_sp10.em\", input_dict)\n",
    "spcsv.write(\"../../../../tests/test_data/point_clouds/motl_040csv_sp10.em\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset normal of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point cloud generated by `boundary_sampling` can also be used to replace the normals in a motl_list. The normal of the nearest point to each motl point will be used to update its angle"
=======
    "#Initialize the napari viewer:\n",
    "viewer = napari.Viewer()\n",
    "# Load tomogram and add it to the viewer\n",
    "tomo = mrcfile.open(mrcfolder + padd_num + '.mrc')\n",
    "tomo_data = tomo.data\n",
    "viewer.add_image(tomo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shape layer which is provided in inputs folder\n",
    "polygons = cuboid_sampling.load_shapes(shapefolder+\"040_1_shape.csv\")\n",
    "shapes_layer = viewer.add_shapes(polygons, shape_type='polygon')"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# parameters for making the oversample points in right binning\n",
    "b_factor = 4\n",
    "pal_thickness = 20\n",
    "samp_dist = 10\n",
    "\n",
    "mask = cryomap.read(\"../../../../tests/test_data/point_clouds/masks/040_generated_mask_2.mrc\")\n",
    "# bin mask base on b_factor\n",
    "size = tuple(b_factor*i for i in mask.shape)\n",
    "bin_mask = resize(mask, size, order=0, mode='constant')\n",
    "# generate oversample points using bin mask\n",
    "spmask40 = surfsamp.SamplePoints.load(bin_mask)\n",
    "spmask40.boundary_sampling(sampling_distance = samp_dist)\n",
    "spmask40out,_ = spmask40.inner_and_outer_pc(thickness = pal_thickness*b_factor)\n",
    "# load motl which you want to modified\n",
    "motl = cryomotl.Motl.load('../../../../tests/test_data/point_clouds/motl_040_STAexample.em')\n",
    "spmask40out.reset_normals(motl)\n",
    "motl.write_out('../../../../tests/test_data/point_clouds/motl_040_STArenormal.em')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate surface area"
=======
    "# For own data one has to create the shape layer and draw the polygons\n",
    "shapes_data=viewer.layers[1].data\n",
    "# And save it for future work\n",
    "cuboid_sampling.save_shapes(shapes_data, shapefolder + padd_num +'_'+str(obj_num)+'_shape.csv') # this file is available in the expected_outputs to continue further\n",
    "\n",
    "# The following code will produce the same results only for the 040_1_shape.csv (provided). For newly produced shapes the outcome will be of course different."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface sampling from shapes\n",
    "A list with the same length as the number of shapes could serve as the input for sampling and shifting distances.\n",
    "To exclude both the top and bottom surfaces from oversampling, set tb_dist to 0. Use 1 to exclude the face with a higher z value, or -1 to exclude the face with a smaller z value.\n",
    "Record the shift_dist and tb_dist. This would used for resetting normal."
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# You may notice that spmask has twice the area of spcsv.\n",
    "# This is because the mask input represents a shell, whereas spcsv only considers the outer surface.\n",
    "print(spmask.area)\n",
    "print(spcsv.area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the mask surface and generating a motl_list for multiple tomograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple tomograms, here is an example script to process them all together.\\\n",
    "_User inputs_\n",
    "- _mask_folder: Path to the folder containing input masks._\n",
    "- _output_folder: Path to the folder where the output motl_list files will be saved._\n",
    "- _mask_list: An (V, 3) excel file with information of masks. V is equals to number of ojects and there's one mask for each object._\n",
    "- _pal_thickness: Thickness of the shell in the mask, used to separate the inner and outer layers of the point clouds._\n",
    "- _sampling_dist: the distance between sampling points in pixels._"
=======
    "output_path = './outputs/'\n",
    "shapes_path = './inputs/'\n",
    "overSample_dist = 3\n",
    "shift_dist = 4\n",
    "tb_dist = 0\n",
    "rm_surface = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = os.listdir(shapes_path)\n",
    "for i,name in enumerate(shapes):\n",
    "    if name.endswith(\".csv\"):\n",
    "        tomo_num = int(name[0:3])\n",
    "        obj_num = int(name[4:5])\n",
    "        \n",
    "        if type(overSample_dist) == int:\n",
    "            overSample_dist = overSample_dist\n",
    "        elif type(overSample_dist) == list:\n",
    "            overSample_dist = overSample_dist[i]\n",
    "\n",
    "        if type(shift_dist) == int:\n",
    "            shift_dist = shift_dist\n",
    "        elif type(shift_dist) == list:\n",
    "            shift_dist = shift_dist[i]\n",
    "\n",
    "        if type(tb_dist) == int:\n",
    "            tb_dist = tb_dist\n",
    "        elif type(tb_dist) == list:\n",
    "            tb_dist = tb_dist[i]\n",
    "\n",
    "        shapes_data=cuboid_sampling.load_shapes(shapes_path+name)\n",
    "        pd_points, pd_angles = cuboid_sampling.get_sampling_pandas(shapes_data, overSample_dist, shift_dist, tb_dist, rm_surface)\n",
    "        pd_motl = cryomotl.EmMotl()\n",
    "        pd_motl.fill({\"coord\": pd_points, \"angles\": pd_angles, \"tomo_id\": tomo_num, \"object_id\":obj_num})\n",
    "        pd_motl.write_out(output_path + str(tomo_num).zfill(3) + '_' + str(obj_num) + '_motl_sp'+ str(overSample_dist) +'.em')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset normal of points"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Sampling and create point clouds base on the surface of the mask. Keep only the outer shell of the pointcloud and save into a motl_list\n",
    "mask_folder = f'../../../../tests/test_data/point_clouds/masks'\n",
    "mask_list = f'../../../../tests/test_data/point_clouds/mask_list.csv'\n",
    "output_folder = f'../../../../tests/test_data/point_clouds/motls'\n",
    "pal_thickness = 20\n",
    "sampling_dist = 5\n",
    "shift_dist = -6\n",
    "\n",
    "# read in mask_list\n",
    "mask_array = pd.read_csv(mask_list, header=None).to_numpy().astype(str)\n",
    "# zero-padded tomo number to 3 digits\n",
    "mask_array[:, 0] = np.char.zfill(mask_array[:, 0], 3)\n",
    "for i in mask_array:\n",
    "    tomo_id, obj_id = i\n",
    "    # file name of input and output\n",
    "    mask_file = f'{tomo_id}_generated_mask_{obj_id}.mrc'\n",
    "    motl_file = f'{tomo_id}_{obj_id}_pointcloud.em'\n",
    "    mask = cryomap.read(f'{mask_folder}/{mask_file}')\n",
    "    # sampling at the surface of mask and keeping only the outer sample points of the shell\n",
    "    sp = surfsamp.SamplePoints.load(mask)\n",
    "    sp.boundary_sampling(sampling_distance = sampling_dist)\n",
    "    outer_sp,_ = sp.inner_and_outer_pc(thickness = pal_thickness)\n",
    "    # shifting coordinates 6 pixels in opposite normal vectors direction. negative value for shifting into direction opposite of the normal vectors\n",
    "    outer_sp.shift_points(shift_dist)\n",
    "    # create input_dict to fill in 'tomo_id' and 'object_id'\n",
    "    input_dict = {'tomo_id':np.ones(outer_sp.vertices.shape[0])*float(tomo_id), 'object_id':np.ones(outer_sp.vertices.shape[0])*float(obj_id)}\n",
    "    outer_sp.write(f'{output_folder}/{motl_file}', input_dict)\n",
    "    print(f'{motl_file} was written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you would like to shift different distance for different normals use method `shift_points_in_groups` with shift_dict input. The shift_dict is a dictionary where keys are tuples representing normal vectors and values are the shift magnitudes in pixels. Here's an example of shifting points with normals pointing out/into the tomogram with a distance in 20 pixels and others in -6 pixels"
=======
    "motl = cryomotl.Motl.load(\"./inputs/dist_clean20_1.em\")\n",
    "motl = motl.get_motl_subset(40)\n",
    "motl.write_out(\"./inputs/dist_clean20_1.em\")"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "shift_dist = -6\n",
    "shift_dist_tb = 10\n",
    "# To create a shift_dict with keys from all normal vectors\n",
    "shift_dict = {key: shift_dist for key in tuple(map(tuple,outer_sp.normals))}\n",
    "# assgin different value for target normal vectors\n",
    "shift_dict[(1,0,0)] = shift_dist_tb\n",
    "shift_dict[(-1,0,0)] = shift_dist_tb\n",
    "# run shift_points_in_groups\n",
    "outer_sp.shift_points_in_groups(shift_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging and renumbering all motls from each object into one"
=======
    "motlfolder = './inputs/dist_clean20_1.em'\n",
    "outfolder = './outputs/dist_clean20_reNorm_1.em'  # available in expected_outputs\n",
    "searching_sampDist = 1 # use small sample distance for searching\n",
    "shifting_dist = 4 # shifting_distance for oversample points\n",
    "tb_move = 0 # same as tb_dist in oversampling\n",
    "binFactor = 4 # bin factor between your shape and motl_list\n",
    "\n",
    "motl = cryomotl.Motl.load(motlfolder)\n",
    "tomoObjNum = motl.df.values[:,4:6]\n",
    "uniTomoObjNum = np.unique(tomoObjNum, axis = 0)\n",
    "tomoNum = 0\n",
    "for i in uniTomoObjNum:\n",
    "    lastTomoNum = tomoNum\n",
    "    tomoNum = int(i[0])\n",
    "    objNum = int(i[1])\n",
    "    if tomoNum == lastTomoNum:\n",
    "        shapesObjNum = shapesObjNum+1\n",
    "    else:\n",
    "        shapesObjNum = 1\n",
    "\n",
    "    # find the rows belongs to the shape \n",
    "    isRow = [i[5] == objNum for i in motl.df.values[:]]\n",
    "    df_motl = motl.df.loc[isRow]\n",
    "\n",
    "    # load plygons shapes\n",
    "    shapes_data = cuboid_sampling.load_shapes(shapefolder + str(tomoNum).zfill(3) +'_' + str(shapesObjNum) + '_shape.csv')\n",
    "    # The motl input of reset_normals needed to be match with the shape\n",
    "    df_motl = cuboid_sampling.reset_normals(searching_sampDist, shifting_dist, tb_move, shapes_data, df_motl, binFactor)\n",
    "    \n",
    "    # insert the updated motl back into motl with mutiple tomograms\n",
    "    motl.df.update(df_motl)\n",
    "\n",
    "cryomotl.Motl.write_out(motl, outfolder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate surface area\n",
    "You have the option to exclude the top or bottom surfaces from the calculation. If you wish to remove both the top and bottom surfaces, you can set rm_faces_all to 0."
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "motl_name = sorted(os.listdir(output_folder))\n",
    "motl_merge = cryomotl.Motl.merge_and_renumber([f'{output_folder}/{i}' for i in motl_name])\n",
    "motl_merge.write_out(f'{output_folder}/allmotl_pcShift-6.em')"
=======
    "pixel_size = 1.56\n",
    "binning = 8\n",
    "rm_faces_all = 0\n",
    "shapes = os.listdir('./outputs/')\n",
    "np_area = np.eye(len(shapes),3)\n",
    "for n,i in enumerate(shapes):\n",
    "    if i.endswith(\".csv\"):\n",
    "        tomo_num = int(i[0:3])\n",
    "        object_num = int(i[4:5]) # not the same with motl list\n",
    "        padd_num = str(tomo_num).zfill(3)\n",
    "        shapes_data=cuboid_sampling.load_shapes(shapefolder+ padd_num +'_' + str(object_num) + '_shape.csv') \n",
    "        if isinstance(shapes_data, list):\n",
    "            # create array from the list\n",
    "            mask_points=np.concatenate(shapes_data, axis=0 )\n",
    "        else:\n",
    "            mask_points=shapes_data\n",
    "        \n",
    "        if rm_faces_all == 0:\n",
    "            rm_faces = rm_faces_all\n",
    "        else:\n",
    "            rm_faces = rm_faces_all[n]\n",
    "\n",
    "        sur_area = cuboid_sampling.get_surface_area_from_hull(mask_points, rm_faces)*(pixel_size**2)*(binning**2)\n",
    "        np_area[n,0] = tomo_num\n",
    "        np_area[n,1] = object_num\n",
    "        np_area[n,2] = sur_area\n",
    "\n",
    "        np.savetxt('./outputs/invitro_area.csv',np_area,delimiter=',')  # available in expected_outputs"
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3 (ipykernel)",
=======
   "display_name": "geo-env",
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
=======
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
>>>>>>> 4309db01a3eac48129183a2f29118786457b28ae
}
